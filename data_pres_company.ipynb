{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Import Libraries",
   "id": "f38557169f6ba35a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T09:55:26.280741Z",
     "start_time": "2024-06-13T09:55:23.008177Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import datetime"
   ],
   "id": "4be8a5b9da5ef907",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Function to create the custom DataFrame",
   "id": "17d2d3b331f43700"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_custom_df(start_date, end_date, tickers, company_names, days):\n",
    "    # Convert start_date and end_date to datetime64[ns]\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "    \n",
    "    # Filter days DataFrame to the specified date range\n",
    "    filtered_days = days[(days['Date'] >= start_date) & (days['Date'] <= end_date)].copy()\n",
    "\n",
    "    # Initialize the custom DataFrame with the filtered days\n",
    "    custom_df = pd.DataFrame(filtered_days['Date'], columns=['Date'])\n",
    "\n",
    "    # Ensure the 'Date' column in the custom_df and all relevant DataFrames is datetime64[ns]\n",
    "    custom_df['Date'] = pd.to_datetime(custom_df['Date'])\n",
    "    \n",
    "    # Add market cap data for the specific tickers\n",
    "    for ticker, name in zip(tickers, company_names):\n",
    "        ticker_data = yf.download(ticker, start=start_date, end=end_date)\n",
    "        if 'Date' not in ticker_data.columns:\n",
    "            ticker_data.reset_index(inplace=True)\n",
    "        print(f\"Merging Market Cap {ticker} ({name}) with {len(ticker_data)} rows\")\n",
    "        custom_df = custom_df.merge(ticker_data[['Date', 'Close']], on='Date', how='left')\n",
    "        custom_df.rename(columns={'Close': name}, inplace=True)\n",
    "\n",
    "    # Remove rows where all elements are NaN except the 'Date' column\n",
    "    custom_df = custom_df.dropna(how='all', subset=custom_df.columns.difference(['Date']))\n",
    "\n",
    "    return custom_df"
   ],
   "id": "723266c757c7532"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Function to normalize the DataFrame",
   "id": "19d56c78865ba90f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def normalize_dataframe(df):\n",
    "    normalized_df = df.copy()\n",
    "    for column in df.columns:\n",
    "        if column != 'Date':\n",
    "            initial_index = df[column].first_valid_index()\n",
    "            if initial_index is None:\n",
    "                print(f\"No valid data for {column}. Skipping normalization for this column.\")\n",
    "                normalized_df[column] = np.nan\n",
    "            else:\n",
    "                initial_value = df.at[initial_index, column]\n",
    "                normalized_df[column] = (df[column] / initial_value) * 100\n",
    "                normalized_df.at[initial_index, column] = 100  # Ensure the first valid value is set to 100\n",
    "    print(f\"Normalized DataFrame:\\n{normalized_df.head()}\")\n",
    "    return normalized_df"
   ],
   "id": "35287d1dc8cfb8a7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create a DataFrame with All Dates",
   "id": "86d4d37b721352bc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "start_date = datetime.date(2024, 1, 1)\n",
    "end_date = datetime.date(2024, 6, 1)\n",
    "days = pd.DataFrame(pd.date_range(start=start_date, end=end_date, freq='D', name='Date'))\n",
    "days['Date'] = pd.to_datetime(days['Date'])"
   ],
   "id": "fd83251d737b11ef"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "List of Tickers and Company Names",
   "id": "b25b45a04deff8c9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "tickers = ['SPNS', 'REAX', 'PERI', 'NVMI', 'INMD', 'CYBR', 'CAMT', 'WIX']\n",
    "company_names = [\n",
    "    'Sapiens International Corporation',\n",
    "    'Real',\n",
    "    'Perion Network',\n",
    "    'Nova Measuring Instruments',\n",
    "    'InMode',\n",
    "    'CyberArk',\n",
    "    'Camtek',\n",
    "    'Wix'\n",
    "]"
   ],
   "id": "413fbfb87210adc1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create the custom DataFrame",
   "id": "cbbe74679cea0a1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging Market Cap SPNS (Sapiens International Corporation) with 105 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging Market Cap REAX (Real) with 105 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging Market Cap PERI (Perion Network) with 105 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging Market Cap NVMI (Nova Measuring Instruments) with 105 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging Market Cap INMD (InMode) with 105 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging Market Cap CYBR (CyberArk) with 105 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging Market Cap CAMT (Camtek) with 105 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging Market Cap WIX (Wix) with 105 rows\n",
      "Custom DataFrame before normalization:\n",
      "        Date  Sapiens International Corporation   Real  Perion Network  \\\n",
      "1 2024-01-02                          28.049999  1.540       30.330000   \n",
      "2 2024-01-03                          26.969999  1.650       29.510000   \n",
      "3 2024-01-04                          26.570000  1.790       29.139999   \n",
      "4 2024-01-05                          26.719999  1.770       28.760000   \n",
      "7 2024-01-08                          27.510000  1.765       29.010000   \n",
      "\n",
      "   Nova Measuring Instruments     InMode    CyberArk     Camtek         Wix  \n",
      "1                  135.649994  22.219999  216.130005  67.459999  118.000000  \n",
      "2                  132.100006  21.000000  214.380005  67.019997  117.400002  \n",
      "3                  131.960007  21.010000  211.679993  68.620003  116.900002  \n",
      "4                  129.320007  20.959999  211.720001  67.930000  118.099998  \n",
      "7                  131.460007  21.370001  217.990005  68.750000  120.459999  \n",
      "Normalized DataFrame:\n",
      "        Date  Sapiens International Corporation        Real  Perion Network  \\\n",
      "1 2024-01-02                         100.000000  100.000000      100.000000   \n",
      "2 2024-01-03                          96.149733  107.142858       97.296407   \n",
      "3 2024-01-04                          94.723709  116.233767       96.076490   \n",
      "4 2024-01-05                          95.258467  114.935067       94.823608   \n",
      "7 2024-01-08                          98.074870  114.610392       95.647874   \n",
      "\n",
      "   Nova Measuring Instruments      InMode    CyberArk      Camtek         Wix  \n",
      "1                  100.000000  100.000000  100.000000  100.000000  100.000000  \n",
      "2                   97.382980   94.509454   99.190302   99.347758   99.491527  \n",
      "3                   97.279773   94.554459   97.941048  101.719543   99.067798  \n",
      "4                   95.333589   94.329432   97.959560  100.696711  100.084744  \n",
      "7                   96.911178   96.174624  100.860593  101.912246  102.084745  \n",
      "DataFrames have been saved to custom_data_with_company_names.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 35,
   "source": [
    "custom_df = create_custom_df(start_date, end_date, tickers, company_names, days)\n",
    "\n",
    "print(f\"Custom DataFrame before normalization:\\n{custom_df.head()}\")\n",
    "normalized_df = normalize_dataframe(custom_df)\n",
    "\n",
    "# Save the custom DataFrame to an Excel file\n",
    "output_file_path = 'custom_data_with_company_names.xlsx'\n",
    "with pd.ExcelWriter(output_file_path) as writer:\n",
    "    custom_df.to_excel(writer, sheet_name='Custom Data', index=False)\n",
    "    normalized_df.to_excel(writer, sheet_name='Normalized Data', index=False)\n",
    "\n",
    "print(f\"DataFrames have been saved to {output_file_path}\")\n"
   ],
   "id": "5413a4421f035954"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Saving DataFrames to Excel",
   "id": "bca731d2edfb39ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T09:55:26.343195Z",
     "start_time": "2024-06-13T09:55:26.282738Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the custom DataFrame and normalized DataFrame to a new Excel file with a graph\n",
    "output_path = 'C:\\\\Users\\\\odeya.h\\\\SNC Dropbox\\\\Odeya Hazani Cohen\\\\פרוייקט\\\\top_compnies_data_2024.xlsx'\n",
    "with pd.ExcelWriter(output_path, engine='xlsxwriter') as writer:\n",
    "    custom_df.to_excel(writer, sheet_name='Custom Data', index=False)\n",
    "    normalized_df.to_excel(writer, sheet_name='Normalized Data', index=False)  "
   ],
   "id": "48e585d334135220",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom data with graph has been saved to C:\\Users\\odeya.h\\SNC Dropbox\\Odeya Hazani Cohen\\פרוייקט\\top_compnies_data_2024.xlsx\n"
     ]
    }
   ],
   "execution_count": 36,
   "source": [
    "    # Create a chart object\n",
    "    workbook  = writer.book\n",
    "    worksheet = writer.sheets['Normalized Data']\n",
    "    chart = workbook.add_chart({'type': 'line'})\n",
    "\n",
    "    # Configure the series of the chart from the DataFrame data\n",
    "    for i, column in enumerate(normalized_df.columns[1:]):  # Skip the 'Date' column\n",
    "        chart.add_series({\n",
    "            'name':       [worksheet.name, 0, i + 1],\n",
    "            'categories': [worksheet.name, 1, 0, len(normalized_df), 0],\n",
    "            'values':     [worksheet.name, 1, i + 1, len(normalized_df), i + 1],\n",
    "        })\n",
    "\n",
    "    # Configure the chart title with professional formatting\n",
    "    chart.set_title({\n",
    "        'name': 'Index Comparison',\n",
    "        'name_font': {\n",
    "            'bold': True,\n",
    "            'size': 14,\n",
    "            'name': 'Arial'\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Configure the chart axes with professional formatting and the new date format\n",
    "    chart.set_x_axis({\n",
    "        'name': 'Date',\n",
    "        'date_axis': True,\n",
    "        'num_format': 'dd-mm-yyyy',\n",
    "        'name_font': {\n",
    "            'bold': True,\n",
    "            'size': 12,\n",
    "            'name': 'Arial'\n",
    "        },\n",
    "        'label_font': {\n",
    "            'size': 10,\n",
    "            'name': 'Arial'\n",
    "        },\n",
    "        'major_gridlines': {\n",
    "            'visible': True,\n",
    "            'line': {'width': 0.75, 'dash_type': 'dash'}\n",
    "        },\n",
    "        'minor_gridlines': {\n",
    "            'visible': True,\n",
    "            'line': {'width': 0.25, 'dash_type': 'dash'}\n",
    "        }\n",
    "    })\n",
    "    chart.set_y_axis({\n",
    "        'name': 'Normalized Value',\n",
    "        'name_font': {\n",
    "            'bold': True,\n",
    "            'size': 12,\n",
    "            'name': 'Arial'\n",
    "        },\n",
    "        'label_font': {\n",
    "            'size': 10,\n",
    "            'name': 'Arial'\n",
    "        },\n",
    "        'major_gridlines': {\n",
    "            'visible': True,\n",
    "            'line': {'width': 0.75, 'dash_type': 'dash'}\n",
    "        },\n",
    "        'minor_gridlines': {\n",
    "            'visible': True,\n",
    "            'line': {'width': 0.25, 'dash_type': 'dash'}\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Customize the legend\n",
    "    chart.set_legend({\n",
    "        'position': 'bottom',\n",
    "        'font': {\n",
    "            'size': 10,\n",
    "            'name': 'Arial'\n",
    "        }\n",
    "    })\n",
    "\n",
    "    # Adjust the chart size and positioning\n",
    "    worksheet.insert_chart('G2', chart, {'x_offset': 25, 'y_offset': 10, 'x_scale': 1.5, 'y_scale': 1.5})\n",
    "\n",
    "print(f\"Custom data with graph has been saved to {output_path}\")\n"
   ],
   "id": "27dc4f8ade7dc38"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
